#!/usr/bin/env python3
"""
æ•°æ®å¯¼å‡ºå·¥å…· - å°†Polymarketæ•°æ®å¯¼å‡ºä¸ºå„ç§æ ¼å¼
"""

import os
import json
import argparse
from datetime import datetime
from typing import Dict, List, Any, Optional
import pandas as pd

class DataExporter:
    def __init__(self, data_dir: str = "./data"):
        self.data_dir = data_dir
        
    def get_all_tag_data(self) -> Dict[str, Dict[str, Any]]:
        """è·å–æ‰€æœ‰æ ‡ç­¾çš„æ•°æ®"""
        tag_dir = os.path.join(self.data_dir, "tag")
        if not os.path.exists(tag_dir):
            return {}
            
        all_data = {}
        
        for tag_name in os.listdir(tag_dir):
            tag_path = os.path.join(tag_dir, tag_name)
            if not os.path.isdir(tag_path):
                continue
                
            # è·å–æœ€æ–°çš„æ–‡ä»¶
            events_files = [f for f in os.listdir(tag_path) if f.startswith("events_") and f.endswith(".csv")]
            markets_files = [f for f in os.listdir(tag_path) if f.startswith("markets_") and f.endswith(".csv")]
            summary_files = [f for f in os.listdir(tag_path) if f.startswith("summary_") and f.endswith(".json")]
            
            if not (events_files and markets_files and summary_files):
                continue
                
            latest_events = sorted(events_files)[-1]
            latest_markets = sorted(markets_files)[-1]
            latest_summary = sorted(summary_files)[-1]
            
            try:
                # è¯»å–æ•°æ®
                events_df = pd.read_csv(os.path.join(tag_path, latest_events))
                markets_df = pd.read_csv(os.path.join(tag_path, latest_markets))
                
                with open(os.path.join(tag_path, latest_summary), "r") as f:
                    summary = json.load(f)
                
                all_data[tag_name] = {
                    "events": events_df,
                    "markets": markets_df,
                    "summary": summary
                }
                
            except Exception as e:
                print(f"âš ï¸  è¯»å–æ ‡ç­¾ {tag_name} æ•°æ®å¤±è´¥: {e}")
                continue
                
        return all_data
    
    def export_to_excel(self, output_file: str, tags: Optional[List[str]] = None):
        """å¯¼å‡ºåˆ°Excelæ–‡ä»¶"""
        all_data = self.get_all_tag_data()
        
        if tags:
            all_data = {k: v for k, v in all_data.items() if k in tags}
        
        if not all_data:
            print("âŒ æ²¡æœ‰æ•°æ®å¯å¯¼å‡º")
            return
            
        print(f"ğŸ“Š å¯¼å‡º {len(all_data)} ä¸ªæ ‡ç­¾çš„æ•°æ®åˆ°Excel...")
        
        with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
            # åˆ›å»ºæ¦‚è§ˆè¡¨
            overview_data = []
            for tag_name, data in all_data.items():
                summary = data["summary"]
                overview_data.append({
                    "æ ‡ç­¾": tag_name,
                    "æ ‡ç­¾åç§°": summary.get("tag_label", tag_name),
                    "äº‹ä»¶æ•°é‡": summary.get("events_count", 0),
                    "å¸‚åœºæ•°é‡": summary.get("markets_count", 0),
                    "æ€»äº¤æ˜“é‡": summary.get("total_volume", 0),
                    "æ€»æµåŠ¨æ€§": summary.get("total_liquidity", 0),
                    "åŒæ­¥æ—¶é—´": summary.get("sync_timestamp", "")
                })
            
            overview_df = pd.DataFrame(overview_data)
            overview_df.to_excel(writer, sheet_name="æ¦‚è§ˆ", index=False)
            
            # ä¸ºæ¯ä¸ªæ ‡ç­¾åˆ›å»ºå·¥ä½œè¡¨
            for tag_name, data in all_data.items():
                # é™åˆ¶å·¥ä½œè¡¨åç§°é•¿åº¦
                sheet_name = tag_name[:30] if len(tag_name) > 30 else tag_name
                
                # äº‹ä»¶æ•°æ®
                events_df = data["events"].copy()
                if not events_df.empty:
                    events_df.to_excel(writer, sheet_name=f"{sheet_name}_äº‹ä»¶", index=False)
                
                # å¸‚åœºæ•°æ®
                markets_df = data["markets"].copy()
                if not markets_df.empty:
                    markets_df.to_excel(writer, sheet_name=f"{sheet_name}_å¸‚åœº", index=False)
        
        print(f"âœ… Excelæ–‡ä»¶å·²ä¿å­˜: {output_file}")
    
    def export_to_json(self, output_file: str, tags: Optional[List[str]] = None):
        """å¯¼å‡ºåˆ°JSONæ–‡ä»¶"""
        all_data = self.get_all_tag_data()
        
        if tags:
            all_data = {k: v for k, v in all_data.items() if k in tags}
        
        if not all_data:
            print("âŒ æ²¡æœ‰æ•°æ®å¯å¯¼å‡º")
            return
            
        print(f"ğŸ“Š å¯¼å‡º {len(all_data)} ä¸ªæ ‡ç­¾çš„æ•°æ®åˆ°JSON...")
        
        # è½¬æ¢DataFrameä¸ºå­—å…¸
        export_data = {}
        for tag_name, data in all_data.items():
            export_data[tag_name] = {
                "summary": data["summary"],
                "events": data["events"].to_dict("records"),
                "markets": data["markets"].to_dict("records")
            }
        
        # æ·»åŠ å…ƒæ•°æ®
        export_data["_metadata"] = {
            "export_time": datetime.now().isoformat(),
            "tags_count": len(all_data),
            "total_events": sum(len(data["events"]) for data in all_data.values()),
            "total_markets": sum(len(data["markets"]) for data in all_data.values())
        }
        
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(export_data, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… JSONæ–‡ä»¶å·²ä¿å­˜: {output_file}")
    
    def export_to_csv_bundle(self, output_dir: str, tags: Optional[List[str]] = None):
        """å¯¼å‡ºåˆ°CSVæ–‡ä»¶åŒ…"""
        all_data = self.get_all_tag_data()
        
        if tags:
            all_data = {k: v for k, v in all_data.items() if k in tags}
        
        if not all_data:
            print("âŒ æ²¡æœ‰æ•°æ®å¯å¯¼å‡º")
            return
            
        os.makedirs(output_dir, exist_ok=True)
        print(f"ğŸ“Š å¯¼å‡º {len(all_data)} ä¸ªæ ‡ç­¾çš„æ•°æ®åˆ°CSVåŒ…...")
        
        # åˆ›å»ºæ¦‚è§ˆæ–‡ä»¶
        overview_data = []
        all_events = []
        all_markets = []
        
        for tag_name, data in all_data.items():
            summary = data["summary"]
            overview_data.append({
                "tag_slug": tag_name,
                "tag_label": summary.get("tag_label", tag_name),
                "events_count": summary.get("events_count", 0),
                "markets_count": summary.get("markets_count", 0),
                "total_volume": summary.get("total_volume", 0),
                "total_liquidity": summary.get("total_liquidity", 0),
                "sync_timestamp": summary.get("sync_timestamp", "")
            })
            
            # æ·»åŠ æ ‡ç­¾ä¿¡æ¯åˆ°äº‹ä»¶å’Œå¸‚åœºæ•°æ®
            events_df = data["events"].copy()
            if not events_df.empty:
                events_df["tag_slug"] = tag_name
                all_events.append(events_df)
            
            markets_df = data["markets"].copy()
            if not markets_df.empty:
                markets_df["tag_slug"] = tag_name
                all_markets.append(markets_df)
        
        # ä¿å­˜æ¦‚è§ˆ
        overview_df = pd.DataFrame(overview_data)
        overview_df.to_csv(os.path.join(output_dir, "overview.csv"), index=False)
        
        # ä¿å­˜åˆå¹¶çš„äº‹ä»¶å’Œå¸‚åœºæ•°æ®
        if all_events:
            combined_events = pd.concat(all_events, ignore_index=True)
            combined_events.to_csv(os.path.join(output_dir, "all_events.csv"), index=False)
        
        if all_markets:
            combined_markets = pd.concat(all_markets, ignore_index=True)
            combined_markets.to_csv(os.path.join(output_dir, "all_markets.csv"), index=False)
        
        # ä¸ºæ¯ä¸ªæ ‡ç­¾åˆ›å»ºå•ç‹¬çš„CSVæ–‡ä»¶
        for tag_name, data in all_data.items():
            tag_dir = os.path.join(output_dir, "by_tag", tag_name)
            os.makedirs(tag_dir, exist_ok=True)
            
            if not data["events"].empty:
                data["events"].to_csv(os.path.join(tag_dir, "events.csv"), index=False)
            
            if not data["markets"].empty:
                data["markets"].to_csv(os.path.join(tag_dir, "markets.csv"), index=False)
            
            # ä¿å­˜æ‘˜è¦
            with open(os.path.join(tag_dir, "summary.json"), "w", encoding="utf-8") as f:
                json.dump(data["summary"], f, indent=2, ensure_ascii=False)
        
        print(f"âœ… CSVåŒ…å·²ä¿å­˜åˆ°: {output_dir}")
    
    def export_summary_report(self, output_file: str):
        """å¯¼å‡ºæ‘˜è¦æŠ¥å‘Š"""
        all_data = self.get_all_tag_data()
        
        if not all_data:
            print("âŒ æ²¡æœ‰æ•°æ®å¯å¯¼å‡º")
            return
            
        print(f"ğŸ“Š ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š...")
        
        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        total_events = sum(len(data["events"]) for data in all_data.values())
        total_markets = sum(len(data["markets"]) for data in all_data.values())
        total_volume = sum(data["summary"].get("total_volume", 0) for data in all_data.values())
        total_liquidity = sum(data["summary"].get("total_liquidity", 0) for data in all_data.values())
        
        # æŒ‰äº¤æ˜“é‡æ’åºæ ‡ç­¾
        sorted_tags = sorted(
            all_data.items(),
            key=lambda x: x[1]["summary"].get("total_volume", 0),
            reverse=True
        )
        
        # ç”ŸæˆæŠ¥å‘Š
        report = []
        report.append("Polymarket æ•°æ®æ‘˜è¦æŠ¥å‘Š")
        report.append("=" * 50)
        report.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")
        report.append("ğŸ“Š æ€»ä½“ç»Ÿè®¡:")
        report.append(f"  æ ‡ç­¾æ•°é‡: {len(all_data)}")
        report.append(f"  äº‹ä»¶æ•°é‡: {total_events}")
        report.append(f"  å¸‚åœºæ•°é‡: {total_markets}")
        report.append(f"  æ€»äº¤æ˜“é‡: ${total_volume:,}")
        report.append(f"  æ€»æµåŠ¨æ€§: ${total_liquidity:,}")
        report.append("")
        report.append("ğŸ·ï¸  æ ‡ç­¾æ’è¡Œ (æŒ‰äº¤æ˜“é‡):")
        
        for i, (tag_name, data) in enumerate(sorted_tags[:20]):
            summary = data["summary"]
            volume = summary.get("total_volume", 0)
            events_count = summary.get("events_count", 0)
            markets_count = summary.get("markets_count", 0)
            
            report.append(f"  {i+1:2d}. {tag_name:15s} - ${volume:>12,} ({events_count:2d} äº‹ä»¶, {markets_count:3d} å¸‚åœº)")
        
        report.append("")
        report.append("ğŸ“ˆ è¯¦ç»†æ ‡ç­¾ä¿¡æ¯:")
        report.append("-" * 80)
        
        for tag_name, data in sorted_tags:
            summary = data["summary"]
            report.append(f"\nğŸ·ï¸  {tag_name} ({summary.get('tag_label', tag_name)})")
            report.append(f"   äº‹ä»¶æ•°é‡: {summary.get('events_count', 0)}")
            report.append(f"   å¸‚åœºæ•°é‡: {summary.get('markets_count', 0)}")
            report.append(f"   äº¤æ˜“é‡: ${summary.get('total_volume', 0):,}")
            report.append(f"   æµåŠ¨æ€§: ${summary.get('total_liquidity', 0):,}")
            
            # æ˜¾ç¤ºçƒ­é—¨äº‹ä»¶
            top_events = summary.get("top_events", [])
            if top_events:
                report.append("   çƒ­é—¨äº‹ä»¶:")
                for event in top_events[:3]:
                    report.append(f"     - {event.get('title', 'N/A')} (${event.get('volume', 0):,})")
        
        # ä¿å­˜æŠ¥å‘Š
        with open(output_file, "w", encoding="utf-8") as f:
            f.write("\n".join(report))
        
        print(f"âœ… æ‘˜è¦æŠ¥å‘Šå·²ä¿å­˜: {output_file}")

def main():
    parser = argparse.ArgumentParser(description="Polymarketæ•°æ®å¯¼å‡ºå·¥å…·")
    parser.add_argument("--data-dir", default="./data", help="æ•°æ®ç›®å½•")
    parser.add_argument("--format", choices=["excel", "json", "csv", "report"], 
                       default="excel", help="å¯¼å‡ºæ ¼å¼")
    parser.add_argument("--output", help="è¾“å‡ºæ–‡ä»¶/ç›®å½•")
    parser.add_argument("--tags", nargs="+", help="æŒ‡å®šè¦å¯¼å‡ºçš„æ ‡ç­¾")
    
    args = parser.parse_args()
    
    exporter = DataExporter(args.data_dir)
    
    # ç”Ÿæˆé»˜è®¤è¾“å‡ºæ–‡ä»¶å
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    if args.format == "excel":
        output_file = args.output or f"polymarket_data_{timestamp}.xlsx"
        exporter.export_to_excel(output_file, args.tags)
        
    elif args.format == "json":
        output_file = args.output or f"polymarket_data_{timestamp}.json"
        exporter.export_to_json(output_file, args.tags)
        
    elif args.format == "csv":
        output_dir = args.output or f"polymarket_csv_{timestamp}"
        exporter.export_to_csv_bundle(output_dir, args.tags)
        
    elif args.format == "report":
        output_file = args.output or f"polymarket_report_{timestamp}.txt"
        exporter.export_summary_report(output_file)

if __name__ == "__main__":
    main()