#!/usr/bin/env python3
"""
ç´§æ€¥å¸‚åœºåŒæ­¥å™¨ - è·å–15åˆ†é’Ÿå†…ç»“æŸçš„å¸‚åœºæ•°æ®
åŸºäºenhanced_sync.pyçš„èƒ½åŠ›ï¼Œä¸“é—¨ç”¨äºè·å–å³å°†ç»“æŸçš„å¸‚åœº
"""

import json
import os
import csv
import time
import argparse
import logging
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
import requests
from dateutil import parser as date_parser

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class UrgentMarketsSync:
    def __init__(self, data_dir: str = "./data", max_retries: int = 3):
        self.data_dir = data_dir
        self.max_retries = max_retries
        
        # æ ‡å‡†è¯·æ±‚å¤´
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Accept": "application/json, text/plain, */*",
            "Accept-Language": "en-US,en;q=0.9",
            "Referer": "https://polymarket.com/"
        }
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        for subdir in ["urgent", "sync_logs", "reports"]:
            os.makedirs(os.path.join(data_dir, subdir), exist_ok=True)

    def make_api_request(self, url: str, params: Optional[Dict] = None, timeout: int = 30) -> Optional[Dict]:
        """
        å‘é€APIè¯·æ±‚ï¼ŒåŒ…å«é‡è¯•æœºåˆ¶å’Œé”™è¯¯å¤„ç†
        """
        for attempt in range(self.max_retries):
            try:
                response = requests.get(url, params=params, headers=self.headers, timeout=timeout)
                
                # å¤„ç†ä¸åŒçš„HTTPçŠ¶æ€ç 
                if response.status_code == 500:
                    logger.warning(f"æœåŠ¡å™¨é”™è¯¯ (500) - ç¬¬{attempt + 1}æ¬¡é‡è¯•ï¼Œç­‰å¾…5ç§’...")
                    time.sleep(5)
                    continue
                elif response.status_code == 429:
                    logger.warning(f"è¯·æ±‚é™åˆ¶ (429) - ç¬¬{attempt + 1}æ¬¡é‡è¯•ï¼Œç­‰å¾…10ç§’...")
                    time.sleep(10)
                    continue
                elif response.status_code == 404:
                    logger.warning(f"èµ„æºæœªæ‰¾åˆ° (404): {url}")
                    return None
                elif response.status_code != 200:
                    logger.error(f"APIé”™è¯¯ {response.status_code}: {response.text[:200]}")
                    if attempt < self.max_retries - 1:
                        logger.info(f"ç¬¬{attempt + 1}æ¬¡é‡è¯•ï¼Œç­‰å¾…3ç§’...")
                        time.sleep(3)
                        continue
                    else:
                        return None
                
                # å°è¯•è§£æJSON
                try:
                    return response.json()
                except json.JSONDecodeError as e:
                    logger.error(f"JSONè§£æå¤±è´¥: {e}")
                    if response.text.strip():
                        logger.error(f"å“åº”å†…å®¹: {response.text[:500]}")
                    return None
                    
            except requests.exceptions.RequestException as e:
                logger.error(f"ç½‘ç»œé”™è¯¯ (ç¬¬{attempt + 1}æ¬¡): {e}")
                if attempt < self.max_retries - 1:
                    time.sleep(5)
                    continue
                else:
                    return None
            except Exception as e:
                logger.error(f"æ„å¤–é”™è¯¯ (ç¬¬{attempt + 1}æ¬¡): {e}")
                if attempt < self.max_retries - 1:
                    time.sleep(3)
                    continue
                else:
                    return None
        
        return None

    def is_ending_soon(self, end_date_str: str, minutes_threshold: int = 15) -> bool:
        """
        æ£€æŸ¥å¸‚åœºæ˜¯å¦åœ¨æŒ‡å®šåˆ†é’Ÿå†…ç»“æŸ
        
        Args:
            end_date_str: ç»“æŸæ—¥æœŸå­—ç¬¦ä¸²
            minutes_threshold: åˆ†é’Ÿé˜ˆå€¼ï¼Œé»˜è®¤15åˆ†é’Ÿ
            
        Returns:
            bool: æ˜¯å¦å³å°†ç»“æŸ
        """
        if not end_date_str:
            return False
            
        try:
            # è§£æç»“æŸæ—¶é—´
            end_time = date_parser.parse(end_date_str)
            current_time = datetime.now(end_time.tzinfo) if end_time.tzinfo else datetime.now()
            
            # è®¡ç®—æ—¶é—´å·®
            time_diff = end_time - current_time
            
            # æ£€æŸ¥æ˜¯å¦åœ¨é˜ˆå€¼å†…ä¸”æœªè¿‡æœŸ
            return 0 < time_diff.total_seconds() <= (minutes_threshold * 60)
            
        except Exception as e:
            logger.error(f"è§£ææ—¥æœŸå¤±è´¥ {end_date_str}: {e}")
            return False

    def get_urgent_markets(self, minutes_threshold: int = 15, batch_size: int = 100) -> List[Dict]:
        """
        è·å–å³å°†ç»“æŸçš„å¸‚åœºæ•°æ®
        
        Args:
            minutes_threshold: åˆ†é’Ÿé˜ˆå€¼ï¼Œé»˜è®¤15åˆ†é’Ÿ
            batch_size: æ‰¹æ¬¡å¤§å°
            
        Returns:
            List[Dict]: å³å°†ç»“æŸçš„å¸‚åœºåˆ—è¡¨
        """
        base_url = "https://gamma-api.polymarket.com/markets"
        urgent_markets = []
        offset = 0
        total_checked = 0
        
        logger.info(f"ğŸ” å¼€å§‹æœç´¢{minutes_threshold}åˆ†é’Ÿå†…ç»“æŸçš„å¸‚åœº...")
        
        while True:
            logger.info(f"æ£€æŸ¥åç§»é‡ {offset} çš„æ‰¹æ¬¡æ•°æ®...")
            
            params = {
                'order': 'endDate',  # æŒ‰ç»“æŸæ—¶é—´æ’åº
                'closed': 'false',   # åªè·å–æœªå…³é—­çš„å¸‚åœº
                'ascending': 'true', # å‡åºæ’åˆ—ï¼Œæœ€å¿«ç»“æŸçš„åœ¨å‰é¢
                'limit': batch_size,
                'offset': offset
            }
            
            data = self.make_api_request(base_url, params)
            
            if not data:
                logger.error(f"æ— æ³•è·å–åç§»é‡ {offset} çš„æ•°æ®")
                break
            
            markets = data if isinstance(data, list) else data.get('data', [])
            
            if not markets:
                logger.info(f"åœ¨åç§»é‡ {offset} æ²¡æœ‰æ‰¾åˆ°æ›´å¤šå¸‚åœº")
                break
            
            # æ£€æŸ¥æ¯ä¸ªå¸‚åœº
            found_in_batch = 0
            for market in markets:
                total_checked += 1
                end_date = market.get('endDate', '')
                
                if self.is_ending_soon(end_date, minutes_threshold):
                    urgent_markets.append(market)
                    found_in_batch += 1
                    logger.info(f"âš¡ å‘ç°ç´§æ€¥å¸‚åœº: {market.get('question', 'Unknown')[:60]}... (ç»“æŸæ—¶é—´: {end_date})")
                elif end_date:
                    # å¦‚æœå½“å‰å¸‚åœºçš„ç»“æŸæ—¶é—´å·²ç»è¶…è¿‡é˜ˆå€¼ï¼Œä¸”æ˜¯æŒ‰æ—¶é—´æ’åºçš„ï¼Œå¯ä»¥è€ƒè™‘åœæ­¢
                    try:
                        end_time = date_parser.parse(end_date)
                        current_time = datetime.now(end_time.tzinfo) if end_time.tzinfo else datetime.now()
                        time_diff = end_time - current_time
                        
                        # å¦‚æœæ—¶é—´å·®è¶…è¿‡é˜ˆå€¼å¤ªå¤šï¼Œå¯èƒ½ä¸éœ€è¦ç»§ç»­æ£€æŸ¥äº†
                        if time_diff.total_seconds() > (minutes_threshold * 60 * 2):  # è¶…è¿‡é˜ˆå€¼2å€
                            logger.info(f"å¸‚åœºç»“æŸæ—¶é—´è¿‡è¿œï¼Œåœæ­¢æœç´¢ (å½“å‰å¸‚åœºç»“æŸæ—¶é—´: {end_date})")
                            break
                    except:
                        pass
            
            logger.info(f"æ‰¹æ¬¡æ£€æŸ¥å®Œæˆ: æ£€æŸ¥äº† {len(markets)} ä¸ªå¸‚åœºï¼Œå‘ç° {found_in_batch} ä¸ªç´§æ€¥å¸‚åœº")
            
            offset += len(markets)
            
            # å¦‚æœè¿™æ‰¹æ•°æ®å°‘äºæ‰¹æ¬¡å¤§å°ï¼Œè¯´æ˜åˆ°è¾¾æœ«å°¾
            if len(markets) < batch_size:
                logger.info(f"å·²æ£€æŸ¥å®Œæ‰€æœ‰å¸‚åœº")
                break
                
            # é˜²æ­¢æ— é™å¾ªç¯ï¼Œè®¾ç½®æœ€å¤§æ£€æŸ¥æ•°é‡
            if total_checked > 10000:
                logger.warning(f"å·²æ£€æŸ¥ {total_checked} ä¸ªå¸‚åœºï¼Œåœæ­¢æœç´¢")
                break
        
        logger.info(f"ğŸ¯ æœç´¢å®Œæˆ: æ€»å…±æ£€æŸ¥äº† {total_checked} ä¸ªå¸‚åœºï¼Œå‘ç° {len(urgent_markets)} ä¸ªç´§æ€¥å¸‚åœº")
        return urgent_markets

    def save_urgent_markets(self, urgent_markets: List[Dict], minutes_threshold: int = 15) -> str:
        """
        ä¿å­˜ç´§æ€¥å¸‚åœºæ•°æ®åˆ°CSVæ–‡ä»¶
        
        Args:
            urgent_markets: ç´§æ€¥å¸‚åœºåˆ—è¡¨
            minutes_threshold: åˆ†é’Ÿé˜ˆå€¼
            
        Returns:
            str: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"urgent_markets_{minutes_threshold}min_{timestamp}.csv"
        full_path = os.path.join(self.data_dir, "urgent", filename)
        
        # CSVæ ‡é¢˜ - ä½¿ç”¨ä¸enhanced_syncç›¸åŒçš„20ä¸ªæ ¸å¿ƒå­—æ®µ
        headers = [
            'id', 'question', 'slug', 'category', 'clobTokenIds', 'outcomes', 
            'outcomePrices', 'conditionId', 'active', 'closed', 'volumeNum', 
            'volume24hr', 'liquidity', 'liquidityNum', 'endDate', 
            'orderPriceMinTickSize', 'orderMinSize', 'resolutionSource', 
            'acceptingOrders', 'openInterest'
        ]
        
        with open(full_path, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow(headers)
            
            for market in urgent_markets:
                try:
                    # å¤„ç†JSONå­—æ®µ
                    def safe_json_field(field_value):
                        """å®‰å…¨å¤„ç†JSONå­—æ®µï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²"""
                        if isinstance(field_value, (list, dict)):
                            return json.dumps(field_value)
                        elif isinstance(field_value, str):
                            return field_value
                        else:
                            return str(field_value) if field_value is not None else ''
                    
                    # åˆ›å»ºæ•°æ®è¡Œï¼ŒæŒ‰ç…§headersé¡ºåº
                    row = [
                        market.get('id', ''),
                        market.get('question', ''),
                        market.get('slug', ''),
                        market.get('category', ''),
                        safe_json_field(market.get('clobTokenIds', '')),
                        safe_json_field(market.get('outcomes', '')),
                        safe_json_field(market.get('outcomePrices', '')),
                        market.get('conditionId', ''),
                        market.get('active', ''),
                        market.get('closed', ''),
                        market.get('volumeNum', ''),
                        market.get('volume24hr', ''),
                        market.get('liquidity', ''),
                        market.get('liquidityNum', ''),
                        market.get('endDate', ''),
                        market.get('orderPriceMinTickSize', ''),
                        market.get('orderMinSize', ''),
                        market.get('resolutionSource', ''),
                        market.get('acceptingOrders', ''),
                        market.get('openInterest', '')
                    ]
                    
                    writer.writerow(row)
                    
                except Exception as e:
                    logger.error(f"å¤„ç†å¸‚åœº {market.get('id', 'unknown')} æ—¶å‡ºé”™: {e}")
                    continue
        
        logger.info(f"ğŸ’¾ ç´§æ€¥å¸‚åœºæ•°æ®å·²ä¿å­˜åˆ°: {full_path}")
        return full_path

    def generate_urgent_report(self, urgent_markets: List[Dict], minutes_threshold: int = 15) -> Dict[str, Any]:
        """
        ç”Ÿæˆç´§æ€¥å¸‚åœºæŠ¥å‘Š
        
        Args:
            urgent_markets: ç´§æ€¥å¸‚åœºåˆ—è¡¨
            minutes_threshold: åˆ†é’Ÿé˜ˆå€¼
            
        Returns:
            Dict: æŠ¥å‘Šæ•°æ®
        """
        current_time = datetime.now()
        
        # æŒ‰ç»“æŸæ—¶é—´æ’åº
        sorted_markets = sorted(urgent_markets, key=lambda x: x.get('endDate', ''))
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_volume = 0
        total_liquidity = 0
        categories = {}
        
        for market in urgent_markets:
            # ç»Ÿè®¡äº¤æ˜“é‡
            try:
                volume = float(market.get('volumeNum', 0) or 0)
                total_volume += volume
            except:
                pass
                
            # ç»Ÿè®¡æµåŠ¨æ€§
            try:
                liquidity = float(market.get('liquidityNum', 0) or 0)
                total_liquidity += liquidity
            except:
                pass
                
            # ç»Ÿè®¡åˆ†ç±»
            category = market.get('category', 'Unknown')
            if category:
                categories[category] = categories.get(category, 0) + 1
        
        report = {
            "timestamp": current_time.isoformat(),
            "minutes_threshold": minutes_threshold,
            "total_urgent_markets": len(urgent_markets),
            "total_volume": total_volume,
            "total_liquidity": total_liquidity,
            "categories": categories,
            "top_markets": []
        }
        
        # æ·»åŠ å‰10ä¸ªæœ€ç´§æ€¥çš„å¸‚åœº
        for i, market in enumerate(sorted_markets[:10]):
            end_date = market.get('endDate', '')
            time_remaining = "Unknown"
            
            if end_date:
                try:
                    end_time = date_parser.parse(end_date)
                    current_time_tz = datetime.now(end_time.tzinfo) if end_time.tzinfo else datetime.now()
                    time_diff = end_time - current_time_tz
                    minutes_remaining = int(time_diff.total_seconds() / 60)
                    time_remaining = f"{minutes_remaining}åˆ†é’Ÿ"
                except:
                    pass
            
            report["top_markets"].append({
                "rank": i + 1,
                "id": market.get('id', ''),
                "question": market.get('question', '')[:100],
                "endDate": end_date,
                "time_remaining": time_remaining,
                "volume": market.get('volumeNum', 0),
                "liquidity": market.get('liquidityNum', 0)
            })
        
        return report

    def print_urgent_summary(self, urgent_markets: List[Dict], minutes_threshold: int = 15):
        """
        æ‰“å°ç´§æ€¥å¸‚åœºæ‘˜è¦
        """
        report = self.generate_urgent_report(urgent_markets, minutes_threshold)
        
        print("\n" + "="*80)
        print(f"âš¡ ç´§æ€¥å¸‚åœºæŠ¥å‘Š - {minutes_threshold}åˆ†é’Ÿå†…ç»“æŸ")
        print("="*80)
        print(f"ğŸ• æŠ¥å‘Šæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ğŸ¯ å‘ç°ç´§æ€¥å¸‚åœº: {report['total_urgent_markets']} ä¸ª")
        print(f"ğŸ’° æ€»äº¤æ˜“é‡: ${report['total_volume']:,.2f}")
        print(f"ğŸ’§ æ€»æµåŠ¨æ€§: ${report['total_liquidity']:,.2f}")
        
        if report['categories']:
            print(f"\nğŸ“Š åˆ†ç±»ç»Ÿè®¡:")
            for category, count in sorted(report['categories'].items(), key=lambda x: x[1], reverse=True):
                if category and category != 'Unknown':
                    print(f"   {category}: {count} ä¸ªå¸‚åœº")
        
        if report['top_markets']:
            print(f"\nğŸ”¥ æœ€ç´§æ€¥çš„å¸‚åœº (å‰{len(report['top_markets'])}ä¸ª):")
            for market in report['top_markets']:
                print(f"   {market['rank']:2d}. [{market['time_remaining']}] {market['question']}")
                print(f"       ID: {market['id']} | äº¤æ˜“é‡: ${market['volume']:,.0f}")
        
        print("="*80)

    def run_urgent_sync(self, minutes_threshold: int = 15, save_to_file: bool = True) -> Dict[str, Any]:
        """
        è¿è¡Œç´§æ€¥å¸‚åœºåŒæ­¥
        
        Args:
            minutes_threshold: åˆ†é’Ÿé˜ˆå€¼
            save_to_file: æ˜¯å¦ä¿å­˜åˆ°æ–‡ä»¶
            
        Returns:
            Dict: åŒæ­¥ç»“æœ
        """
        start_time = datetime.now()
        logger.info(f"ğŸš€ å¼€å§‹ç´§æ€¥å¸‚åœºåŒæ­¥ (é˜ˆå€¼: {minutes_threshold}åˆ†é’Ÿ)")
        
        try:
            # è·å–ç´§æ€¥å¸‚åœº
            urgent_markets = self.get_urgent_markets(minutes_threshold)
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            csv_file = None
            if save_to_file and urgent_markets:
                csv_file = self.save_urgent_markets(urgent_markets, minutes_threshold)
            
            # ç”ŸæˆæŠ¥å‘Š
            report = self.generate_urgent_report(urgent_markets, minutes_threshold)
            
            # ä¿å­˜JSONæŠ¥å‘Š
            if save_to_file:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                json_file = os.path.join(self.data_dir, "reports", f"urgent_report_{minutes_threshold}min_{timestamp}.json")
                with open(json_file, "w", encoding='utf-8') as f:
                    json.dump(report, f, indent=2, ensure_ascii=False)
                logger.info(f"ğŸ“Š æŠ¥å‘Šå·²ä¿å­˜åˆ°: {json_file}")
            
            # æ‰“å°æ‘˜è¦
            self.print_urgent_summary(urgent_markets, minutes_threshold)
            
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            
            return {
                "success": True,
                "urgent_markets_count": len(urgent_markets),
                "csv_file": csv_file,
                "duration_seconds": duration,
                "report": report
            }
            
        except Exception as e:
            logger.error(f"ç´§æ€¥å¸‚åœºåŒæ­¥å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "urgent_markets_count": 0
            }

def main():
    parser = argparse.ArgumentParser(description="ç´§æ€¥å¸‚åœºåŒæ­¥å™¨ - è·å–å³å°†ç»“æŸçš„å¸‚åœº")
    parser.add_argument("--data-dir", default="./data", help="æ•°æ®ç›®å½•")
    parser.add_argument("--minutes", type=int, default=15, help="åˆ†é’Ÿé˜ˆå€¼ (é»˜è®¤15åˆ†é’Ÿ)")
    parser.add_argument("--no-save", action="store_true", help="ä¸ä¿å­˜åˆ°æ–‡ä»¶ï¼Œä»…æ˜¾ç¤ºç»“æœ")
    parser.add_argument("--debug", action="store_true", help="å¯ç”¨è°ƒè¯•æ—¥å¿—")
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    if args.debug:
        logging.getLogger().setLevel(logging.DEBUG)
    
    syncer = UrgentMarketsSync(data_dir=args.data_dir)
    
    result = syncer.run_urgent_sync(
        minutes_threshold=args.minutes,
        save_to_file=not args.no_save
    )
    
    if result["success"]:
        print(f"\nâœ… ç´§æ€¥å¸‚åœºåŒæ­¥å®Œæˆ!")
        print(f"   å‘ç°ç´§æ€¥å¸‚åœº: {result['urgent_markets_count']} ä¸ª")
        print(f"   è€—æ—¶: {result['duration_seconds']:.1f} ç§’")
        if result.get("csv_file"):
            print(f"   æ•°æ®æ–‡ä»¶: {result['csv_file']}")
    else:
        print(f"\nâŒ ç´§æ€¥å¸‚åœºåŒæ­¥å¤±è´¥: {result.get('error', 'Unknown error')}")

if __name__ == "__main__":
    main()