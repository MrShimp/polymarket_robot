#!/usr/bin/env python3
"""
å¸‚åœºæœç´¢å·¥å…· - é€šè¿‡å…³é”®è¯æœç´¢Polymarketå¸‚åœº
ä½¿ç”¨å…¬å…±æœç´¢API: https://gamma-api.polymarket.com/public-search
"""

import json
import os
import csv
import time
import argparse
import logging
from datetime import datetime
from typing import List, Dict, Any, Optional
import requests
from dateutil import parser as date_parser

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class MarketSearcher:
    def __init__(self, data_dir: str = "./data", max_retries: int = 3):
        self.data_dir = data_dir
        self.max_retries = max_retries
        
        # æ ‡å‡†è¯·æ±‚å¤´
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Accept": "application/json, text/plain, */*",
            "Accept-Language": "en-US,en;q=0.9",
            "Referer": "https://polymarket.com/"
        }
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        for subdir in ["markets", "search_logs", "reports"]:
            os.makedirs(os.path.join(data_dir, subdir), exist_ok=True)

    def make_api_request(self, url: str, params: Optional[Dict] = None, timeout: int = 30) -> Optional[Dict]:
        """
        å‘é€APIè¯·æ±‚ï¼ŒåŒ…å«é‡è¯•æœºåˆ¶å’Œé”™è¯¯å¤„ç†
        """
        for attempt in range(self.max_retries):
            try:
                response = requests.get(url, params=params, headers=self.headers, timeout=timeout)
                
                # å¤„ç†ä¸åŒçš„HTTPçŠ¶æ€ç 
                if response.status_code == 500:
                    logger.warning(f"æœåŠ¡å™¨é”™è¯¯ (500) - ç¬¬{attempt + 1}æ¬¡é‡è¯•ï¼Œç­‰å¾…5ç§’...")
                    time.sleep(5)
                    continue
                elif response.status_code == 429:
                    logger.warning(f"è¯·æ±‚é™åˆ¶ (429) - ç¬¬{attempt + 1}æ¬¡é‡è¯•ï¼Œç­‰å¾…10ç§’...")
                    time.sleep(10)
                    continue
                elif response.status_code == 404:
                    logger.warning(f"èµ„æºæœªæ‰¾åˆ° (404): {url}")
                    return None
                elif response.status_code != 200:
                    logger.error(f"APIé”™è¯¯ {response.status_code}: {response.text[:200]}")
                    if attempt < self.max_retries - 1:
                        logger.info(f"ç¬¬{attempt + 1}æ¬¡é‡è¯•ï¼Œç­‰å¾…3ç§’...")
                        time.sleep(3)
                        continue
                    else:
                        return None
                
                # å°è¯•è§£æJSON
                try:
                    return response.json()
                except json.JSONDecodeError as e:
                    logger.error(f"JSONè§£æå¤±è´¥: {e}")
                    if response.text.strip():
                        logger.error(f"å“åº”å†…å®¹: {response.text[:500]}")
                    return None
                    
            except requests.exceptions.RequestException as e:
                logger.error(f"ç½‘ç»œé”™è¯¯ (ç¬¬{attempt + 1}æ¬¡): {e}")
                if attempt < self.max_retries - 1:
                    time.sleep(5)
                    continue
                else:
                    return None
            except Exception as e:
                logger.error(f"æ„å¤–é”™è¯¯ (ç¬¬{attempt + 1}æ¬¡): {e}")
                if attempt < self.max_retries - 1:
                    time.sleep(3)
                    continue
                else:
                    return None
        
        return None

    def filter_active_markets(self, markets: List[Dict]) -> List[Dict]:
        """
        è¿‡æ»¤å‡ºæ´»è·ƒçš„ã€æœªç»“æŸçš„å¸‚åœº
        
        Args:
            markets: åŸå§‹å¸‚åœºåˆ—è¡¨
            
        Returns:
            List[Dict]: è¿‡æ»¤åçš„æ´»è·ƒå¸‚åœºåˆ—è¡¨
        """
        active_markets = []
        current_time = datetime.now()
        
        for market in markets:
            # æ£€æŸ¥å¸‚åœºæ˜¯å¦å·²å…³é—­
            if market.get('closed', False):
                continue
            
            # æ£€æŸ¥å¸‚åœºæ˜¯å¦æ´»è·ƒ
            if not market.get('active', True):
                continue
            
            # æ£€æŸ¥ç»“æŸæ—¶é—´
            end_date = market.get('endDate', '')
            if end_date:
                try:
                    end_time = date_parser.parse(end_date)
                    current_time_tz = datetime.now(end_time.tzinfo) if end_time.tzinfo else datetime.now()
                    
                    # å¦‚æœå¸‚åœºå·²ç»è¿‡æœŸï¼Œè·³è¿‡
                    if end_time <= current_time_tz:
                        continue
                except:
                    # å¦‚æœæ— æ³•è§£ææ—¶é—´ï¼Œä¿ç•™å¸‚åœºï¼ˆå¯èƒ½æ˜¯æ°¸ä¹…å¸‚åœºï¼‰
                    pass
            
            active_markets.append(market)
        
        return active_markets

    def search_markets(self, query: str, limit: int = 100, active_only: bool = True) -> List[Dict]:
        """
        é€šè¿‡å…³é”®è¯æœç´¢å¸‚åœº
        
        Args:
            query: æœç´¢å…³é”®è¯
            limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶
            active_only: æ˜¯å¦åªè¿”å›æ´»è·ƒå¸‚åœº
            
        Returns:
            List[Dict]: åŒ¹é…çš„å¸‚åœºåˆ—è¡¨
        """
        base_url = "https://gamma-api.polymarket.com/public-search"
        
        logger.info(f"ğŸ” æœç´¢å…³é”®è¯ '{query}' çš„å¸‚åœº...")
        
        # å¢åŠ æœç´¢é™åˆ¶ä»¥è·å¾—æ›´å¤šç»“æœï¼Œç„¶åè¿‡æ»¤
        search_limit = limit * 3 if active_only else limit
        
        params = {
            'q': query,
            'limit': search_limit
        }
        
        data = self.make_api_request(base_url, params)
        
        if not data:
            logger.warning(f"æ— æ³•è·å–å…³é”®è¯ '{query}' çš„æœç´¢ç»“æœ")
            return []
        
        # æ£€æŸ¥å“åº”ç»“æ„
        if isinstance(data, dict):
            markets = data.get('events', [])  # ä½¿ç”¨ 'events' è€Œä¸æ˜¯ 'markets'
            if not markets:
                # å°è¯•å…¶ä»–å¯èƒ½çš„å­—æ®µå
                markets = data.get('markets', [])
                if not markets:
                    markets = data.get('data', [])
                    if not markets:
                        markets = data.get('results', [])
        elif isinstance(data, list):
            markets = data
        else:
            logger.error(f"æ„å¤–çš„å“åº”æ ¼å¼: {type(data)}")
            return []
        
        original_count = len(markets)
        
        # å¦‚æœåªè¦æ´»è·ƒå¸‚åœºï¼Œè¿›è¡Œè¿‡æ»¤
        if active_only:
            markets = self.filter_active_markets(markets)
            logger.info(f"ğŸ”„ è¿‡æ»¤åå‰©ä½™ {len(markets)} ä¸ªæ´»è·ƒå¸‚åœºï¼ˆåŸå§‹: {original_count} ä¸ªï¼‰")
            
            # é™åˆ¶è¿”å›æ•°é‡
            markets = markets[:limit]
        
        logger.info(f"âœ… å…³é”®è¯ '{query}' æœç´¢å®Œæˆ: æ‰¾åˆ° {len(markets)} ä¸ªå¸‚åœº")
        return markets

    def save_markets_data(self, markets: List[Dict], keyword: str) -> str:
        """
        ä¿å­˜å¸‚åœºæ•°æ®åˆ°CSVæ–‡ä»¶
        
        Args:
            markets: å¸‚åœºåˆ—è¡¨
            keyword: æœç´¢å…³é”®è¯ï¼ˆç”¨äºæ–‡ä»¶å‘½åï¼‰
            
        Returns:
            str: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_keyword = "".join(c for c in keyword if c.isalnum() or c in ('-', '_')).lower()
        filename = f"{safe_keyword}_markets_{timestamp}.csv"
        full_path = os.path.join(self.data_dir, "markets", filename)
        
        # CSVæ ‡é¢˜
        headers = [
            'id', 'question', 'slug', 'category', 'tags', 'clobTokenIds', 'outcomes', 
            'outcomePrices', 'conditionId', 'active', 'closed', 'volumeNum', 
            'volume24hr', 'liquidity', 'liquidityNum', 'endDate', 
            'orderPriceMinTickSize', 'orderMinSize', 'resolutionSource', 
            'acceptingOrders', 'openInterest', 'createdAt', 'updatedAt',
            'description', 'image', 'icon', 'enableOrderBook', 'marketMakerAddress',
            'funded', 'groupItemTitle', 'groupItemThreshold'
        ]
        
        with open(full_path, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow(headers)
            
            for market in markets:
                try:
                    # å¤„ç†JSONå­—æ®µ
                    def safe_json_field(field_value):
                        """å®‰å…¨å¤„ç†JSONå­—æ®µï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²"""
                        if isinstance(field_value, (list, dict)):
                            return json.dumps(field_value, ensure_ascii=False)
                        elif isinstance(field_value, str):
                            return field_value
                        else:
                            return str(field_value) if field_value is not None else ''
                    
                    # åˆ›å»ºæ•°æ®è¡Œ
                    row = [
                        market.get('id', ''),
                        market.get('title', market.get('question', '')),  # ä¼˜å…ˆä½¿ç”¨titleå­—æ®µ
                        market.get('slug', ''),
                        market.get('category', ''),
                        safe_json_field(market.get('tags', '')),
                        safe_json_field(market.get('clobTokenIds', '')),
                        safe_json_field(market.get('outcomes', '')),
                        safe_json_field(market.get('outcomePrices', '')),
                        market.get('conditionId', ''),
                        market.get('active', ''),
                        market.get('closed', ''),
                        market.get('volumeNum', ''),
                        market.get('volume24hr', ''),
                        market.get('liquidity', ''),
                        market.get('liquidityNum', ''),
                        market.get('endDate', ''),
                        market.get('orderPriceMinTickSize', ''),
                        market.get('orderMinSize', ''),
                        market.get('resolutionSource', ''),
                        market.get('acceptingOrders', ''),
                        market.get('openInterest', ''),
                        market.get('createdAt', ''),
                        market.get('updatedAt', ''),
                        market.get('description', ''),
                        market.get('image', ''),
                        market.get('icon', ''),
                        market.get('enableOrderBook', ''),
                        market.get('marketMakerAddress', ''),
                        market.get('funded', ''),
                        market.get('groupItemTitle', ''),
                        market.get('groupItemThreshold', '')
                    ]
                    
                    writer.writerow(row)
                    
                except Exception as e:
                    logger.error(f"å¤„ç†å¸‚åœº {market.get('id', 'unknown')} æ—¶å‡ºé”™: {e}")
                    continue
        
        logger.info(f"ğŸ’¾ å¸‚åœºæ•°æ®å·²ä¿å­˜åˆ°: {full_path}")
        return full_path

    def generate_search_report(self, markets: List[Dict], keyword: str) -> Dict[str, Any]:
        """
        ç”Ÿæˆæœç´¢æŠ¥å‘Š
        
        Args:
            markets: å¸‚åœºåˆ—è¡¨
            keyword: æœç´¢å…³é”®è¯
            
        Returns:
            Dict: æŠ¥å‘Šæ•°æ®
        """
        current_time = datetime.now()
        
        # æŒ‰äº¤æ˜“é‡æ’åº
        sorted_markets = sorted(markets, key=lambda x: float(x.get('volumeNum', 0) or 0), reverse=True)
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_volume = 0
        total_liquidity = 0
        categories = {}
        active_count = 0
        closed_count = 0
        
        for market in markets:
            # ç»Ÿè®¡äº¤æ˜“é‡
            try:
                volume = float(market.get('volumeNum', 0) or 0)
                total_volume += volume
            except:
                pass
                
            # ç»Ÿè®¡æµåŠ¨æ€§
            try:
                liquidity = float(market.get('liquidityNum', 0) or 0)
                total_liquidity += liquidity
            except:
                pass
                
            # ç»Ÿè®¡åˆ†ç±»
            category = market.get('category', 'Unknown')
            if category:
                categories[category] = categories.get(category, 0) + 1
            
            # ç»Ÿè®¡çŠ¶æ€
            if market.get('active'):
                active_count += 1
            if market.get('closed'):
                closed_count += 1
        
        # æ—¶é—´åˆ†æ
        time_ranges = {
            '1å¤©å†…': 0, '1å‘¨å†…': 0, '1æœˆå†…': 0, '3æœˆå†…': 0, '6æœˆå†…': 0, '1å¹´å†…': 0, '1å¹´ä»¥ä¸Š': 0
        }
        
        for market in markets:
            end_date = market.get('endDate', '')
            if end_date:
                try:
                    end_time = date_parser.parse(end_date)
                    current_time_tz = datetime.now(end_time.tzinfo) if end_time.tzinfo else datetime.now()
                    time_diff = end_time - current_time_tz
                    days = time_diff.days
                    
                    if days <= 1:
                        time_ranges['1å¤©å†…'] += 1
                    elif days <= 7:
                        time_ranges['1å‘¨å†…'] += 1
                    elif days <= 30:
                        time_ranges['1æœˆå†…'] += 1
                    elif days <= 90:
                        time_ranges['3æœˆå†…'] += 1
                    elif days <= 180:
                        time_ranges['6æœˆå†…'] += 1
                    elif days <= 365:
                        time_ranges['1å¹´å†…'] += 1
                    else:
                        time_ranges['1å¹´ä»¥ä¸Š'] += 1
                except:
                    pass
        
        report = {
            "timestamp": current_time.isoformat(),
            "keyword": keyword,
            "total_markets": len(markets),
            "active_markets": active_count,
            "closed_markets": closed_count,
            "total_volume": total_volume,
            "total_liquidity": total_liquidity,
            "categories": categories,
            "time_ranges": time_ranges,
            "top_markets": []
        }
        
        # æ·»åŠ å‰20ä¸ªäº¤æ˜“é‡æœ€å¤§çš„å¸‚åœº
        for i, market in enumerate(sorted_markets[:20]):
            end_date = market.get('endDate', '')
            time_remaining = "Unknown"
            
            if end_date:
                try:
                    end_time = date_parser.parse(end_date)
                    current_time_tz = datetime.now(end_time.tzinfo) if end_time.tzinfo else datetime.now()
                    time_diff = end_time - current_time_tz
                    
                    if time_diff.total_seconds() > 0:
                        days = time_diff.days
                        hours = time_diff.seconds // 3600
                        if days > 0:
                            time_remaining = f"{days}å¤©{hours}å°æ—¶"
                        else:
                            time_remaining = f"{hours}å°æ—¶"
                    else:
                        time_remaining = "å·²è¿‡æœŸ"
                except:
                    pass
            
            report["top_markets"].append({
                "rank": i + 1,
                "id": market.get('id', ''),
                "question": market.get('title', market.get('question', ''))[:100],  # ä¼˜å…ˆä½¿ç”¨titleå­—æ®µ
                "category": market.get('category', ''),
                "endDate": end_date,
                "time_remaining": time_remaining,
                "volume": market.get('volumeNum', 0),
                "liquidity": market.get('liquidityNum', 0),
                "active": market.get('active', False),
                "closed": market.get('closed', False)
            })
        
        return report

    def print_search_summary(self, markets: List[Dict], keyword: str):
        """
        æ‰“å°æœç´¢æ‘˜è¦
        """
        report = self.generate_search_report(markets, keyword)
        
        print("\n" + "="*80)
        print(f"ğŸ” å¸‚åœºæœç´¢æŠ¥å‘Š - '{keyword}'")
        print("="*80)
        print(f"ğŸ• æœç´¢æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ğŸ¯ å‘ç°å¸‚åœº: {report['total_markets']} ä¸ª")
        print(f"âœ… æ´»è·ƒå¸‚åœº: {report['active_markets']} ä¸ª")
        print(f"âŒ å·²å…³é—­: {report['closed_markets']} ä¸ª")
        print(f"ğŸ’° æ€»äº¤æ˜“é‡: ${report['total_volume']:,.2f}")
        print(f"ğŸ’§ æ€»æµåŠ¨æ€§: ${report['total_liquidity']:,.2f}")
        
        if report['categories']:
            print(f"\nğŸ“Š åˆ†ç±»ç»Ÿè®¡:")
            for category, count in sorted(report['categories'].items(), key=lambda x: x[1], reverse=True):
                if category and category != 'Unknown':
                    print(f"   {category}: {count} ä¸ªå¸‚åœº")
        
        if report['time_ranges']:
            print(f"\nâ° ç»“æŸæ—¶é—´åˆ†å¸ƒ:")
            for time_range, count in report['time_ranges'].items():
                if count > 0:
                    print(f"   {time_range}: {count} ä¸ªå¸‚åœº")
        
        if report['top_markets']:
            print(f"\nğŸ”¥ äº¤æ˜“é‡æœ€å¤§çš„å¸‚åœº (å‰{min(10, len(report['top_markets']))}ä¸ª):")
            for market in report['top_markets'][:10]:
                status = "ğŸŸ¢" if market['active'] else "ğŸ”´" if market['closed'] else "âšª"
                print(f"   {market['rank']:2d}. {status} [{market['time_remaining']}] {market['question']}")
                print(f"       ID: {market['id']} | äº¤æ˜“é‡: ${market['volume']:,.0f}")
        
        print("="*80)

    def run_search(self, keyword: str, limit: int = 100, save_to_file: bool = True, active_only: bool = True) -> Dict[str, Any]:
        """
        è¿è¡Œå¸‚åœºæœç´¢
        
        Args:
            keyword: æœç´¢å…³é”®è¯
            limit: ç»“æœæ•°é‡é™åˆ¶
            save_to_file: æ˜¯å¦ä¿å­˜åˆ°æ–‡ä»¶
            active_only: æ˜¯å¦åªè¿”å›æ´»è·ƒå¸‚åœº
            
        Returns:
            Dict: æœç´¢ç»“æœ
        """
        start_time = datetime.now()
        logger.info(f"ğŸš€ å¼€å§‹æœç´¢å…³é”®è¯: {keyword}")
        
        try:
            # æœç´¢å¸‚åœº
            markets = self.search_markets(keyword, limit, active_only)
            
            if not markets:
                return {
                    "success": False,
                    "error": f"æœªæ‰¾åˆ°å…³é”®è¯ '{keyword}' çš„{'æ´»è·ƒ' if active_only else ''}å¸‚åœº",
                    "markets_count": 0
                }
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            csv_file = None
            if save_to_file:
                csv_file = self.save_markets_data(markets, keyword)
            
            # ç”ŸæˆæŠ¥å‘Š
            report = self.generate_search_report(markets, keyword)
            
            # ä¿å­˜JSONæŠ¥å‘Š
            if save_to_file:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                safe_keyword = "".join(c for c in keyword if c.isalnum() or c in ('-', '_')).lower()
                json_file = os.path.join(self.data_dir, "reports", f"search_report_{safe_keyword}_{timestamp}.json")
                with open(json_file, "w", encoding='utf-8') as f:
                    json.dump(report, f, indent=2, ensure_ascii=False)
                logger.info(f"ğŸ“Š æŠ¥å‘Šå·²ä¿å­˜åˆ°: {json_file}")
            
            # æ‰“å°æ‘˜è¦
            self.print_search_summary(markets, keyword)
            
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            
            return {
                "success": True,
                "markets_count": len(markets),
                "csv_file": csv_file,
                "duration_seconds": duration,
                "report": report
            }
            
        except Exception as e:
            logger.error(f"å¸‚åœºæœç´¢å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "markets_count": 0
            }

def main():
    parser = argparse.ArgumentParser(description="å¸‚åœºæœç´¢å·¥å…· - é€šè¿‡å…³é”®è¯æœç´¢Polymarketå¸‚åœº")
    parser.add_argument("keyword", help="æœç´¢å…³é”®è¯")
    parser.add_argument("--data-dir", default="./data", help="æ•°æ®ç›®å½•")
    parser.add_argument("--limit", type=int, default=100, help="è¿”å›ç»“æœæ•°é‡é™åˆ¶")
    parser.add_argument("--include-closed", action="store_true", help="åŒ…å«å·²å…³é—­çš„å¸‚åœº")
    parser.add_argument("--no-save", action="store_true", help="ä¸ä¿å­˜åˆ°æ–‡ä»¶ï¼Œä»…æ˜¾ç¤ºç»“æœ")
    parser.add_argument("--debug", action="store_true", help="å¯ç”¨è°ƒè¯•æ—¥å¿—")
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    if args.debug:
        logging.getLogger().setLevel(logging.DEBUG)
    
    searcher = MarketSearcher(data_dir=args.data_dir)
    
    result = searcher.run_search(
        keyword=args.keyword,
        limit=args.limit,
        save_to_file=not args.no_save,
        active_only=not args.include_closed
    )
    
    if result["success"]:
        print(f"\nâœ… å¸‚åœºæœç´¢å®Œæˆ!")
        print(f"   å‘ç°å¸‚åœº: {result['markets_count']} ä¸ª")
        print(f"   è€—æ—¶: {result['duration_seconds']:.1f} ç§’")
        if result.get("csv_file"):
            print(f"   æ•°æ®æ–‡ä»¶: {result['csv_file']}")
    else:
        print(f"\nâŒ å¸‚åœºæœç´¢å¤±è´¥: {result.get('error', 'Unknown error')}")

if __name__ == "__main__":
    main()