import requests
import json
from typing import Dict, List, Optional, Any
from datetime import datetime
import logging
import os
import csv

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class PolymarketMarketClient:
    """
    Polymarket Market APIå®¢æˆ·ç«¯
    åŸºäºGamma API: https://gamma-api.polymarket.com
    """
    
    def __init__(self, 
                 base_url: str = "https://gamma-api.polymarket.com",
                 save_data: bool = True):
        self.base_url = base_url
        self.save_data = save_data
        self.session = requests.Session()
        
        # è®¾ç½®åŸºç¡€è¯·æ±‚å¤´
        self.session.headers.update({
            'Content-Type': 'application/json',
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'en-US,en;q=0.9',
            'Referer': 'https://polymarket.com/'
        })
    
    def _save_to_csv(self, data: List[Dict], filename: str):
        """ç®€å•çš„CSVä¿å­˜åŠŸèƒ½"""
        if not data or not self.save_data:
            return
        
        try:
            os.makedirs("data/api_cache", exist_ok=True)
            filepath = f"data/api_cache/{filename}"
            
            with open(filepath, 'w', newline='', encoding='utf-8') as f:
                if data:
                    writer = csv.DictWriter(f, fieldnames=data[0].keys())
                    writer.writeheader()
                    writer.writerows(data)
        except Exception as e:
            logger.warning(f"Failed to save data to {filename}: {e}")
    
    def get_events(self, 
                   active: Optional[bool] = None,
                   closed: Optional[bool] = None,
                   limit: Optional[int] = None,
                   offset: Optional[int] = None,
                   order: Optional[str] = None,
                   order_by: Optional[str] = None,
                   slug: Optional[str] = None) -> Optional[List[Dict[str, Any]]]:
        """
        è·å–äº‹ä»¶åˆ—è¡¨
        
        Args:
            active: æ˜¯å¦åªè¿”å›æ´»è·ƒäº‹ä»¶
            closed: æ˜¯å¦åªè¿”å›å·²å…³é—­äº‹ä»¶
            limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶
            offset: åç§»é‡
            order: æ’åºæ–¹å‘ (asc/desc)
            order_by: æ’åºå­—æ®µ
            slug: äº‹ä»¶slugç­›é€‰
            
        Returns:
            äº‹ä»¶åˆ—è¡¨æˆ–None
        """
        try:
            url = f"{self.base_url}/events"
            params = {}
            
            if active is not None:
                params['active'] = str(active).lower()
            if closed is not None:
                params['closed'] = str(closed).lower()
            if limit is not None:
                params['limit'] = limit
            if offset is not None:
                params['offset'] = offset
            if order:
                params['order'] = order
            if order_by:
                params['order_by'] = order_by
            if slug:
                params['slug'] = slug
            
            response = self.session.get(url, params=params, timeout=10)
            response.raise_for_status()
            
            events_data = response.json()
            
            logger.info(f"æˆåŠŸè·å– {len(events_data)} ä¸ªäº‹ä»¶")
            
            # ä¿å­˜æ•°æ®åˆ°CSV
            if self.save_data and events_data:
                self._save_to_csv(events_data, "events_list.csv")
            
            return events_data
            
        except requests.exceptions.RequestException as e:
            logger.error(f"è·å–äº‹ä»¶åˆ—è¡¨å¤±è´¥: {e}")
            return None
    
    def get_event_by_slug(self, slug: str) -> Optional[Dict[str, Any]]:
        """
        æ ¹æ®slugè·å–ç‰¹å®šäº‹ä»¶
        
        Args:
            slug: äº‹ä»¶slug
            
        Returns:
            äº‹ä»¶æ•°æ®æˆ–None
        """
        try:
            url = f"{self.base_url}/events/{slug}"
            response = self.session.get(url, timeout=10)
            response.raise_for_status()
            
            event_data = response.json()
            logger.info(f"æˆåŠŸè·å–äº‹ä»¶: {slug}")
            
            # ä¿å­˜æ•°æ®åˆ°CSV
            if self.save_data and event_data:
                self._save_to_csv([event_data], f"event_{event_slug}.csv")
            
            return event_data
            
        except requests.exceptions.RequestException as e:
            logger.error(f"è·å–äº‹ä»¶è¯¦æƒ…å¤±è´¥: {e}")
            return None
    
    def get_markets(self,
                   active: Optional[bool] = None,
                   closed: Optional[bool] = None,
                   limit: Optional[int] = None,
                   offset: Optional[int] = None,
                   order: Optional[str] = None,
                   order_by: Optional[str] = None,
                   event_slug: Optional[str] = None) -> Optional[List[Dict[str, Any]]]:
        """
        è·å–å¸‚åœºåˆ—è¡¨
        
        Args:
            active: æ˜¯å¦åªè¿”å›æ´»è·ƒå¸‚åœº
            closed: æ˜¯å¦åªè¿”å›å·²å…³é—­å¸‚åœº
            limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶
            offset: åç§»é‡
            order: æ’åºæ–¹å‘ (asc/desc)
            order_by: æ’åºå­—æ®µ
            event_slug: äº‹ä»¶slugç­›é€‰
            
        Returns:
            å¸‚åœºåˆ—è¡¨æˆ–None
        """
        try:
            url = f"{self.base_url}/markets"
            params = {}
            
            if active is not None:
                params['active'] = str(active).lower()
            if closed is not None:
                params['closed'] = str(closed).lower()
            if limit is not None:
                params['limit'] = limit
            if offset is not None:
                params['offset'] = offset
            if order:
                params['order'] = order
            if order_by:
                params['order_by'] = order_by
            if event_slug:
                params['event_slug'] = event_slug
            
            response = self.session.get(url, params=params, timeout=10)
            response.raise_for_status()
            
            markets_data = response.json()
            
            logger.info(f"æˆåŠŸè·å– {len(markets_data)} ä¸ªå¸‚åœº")
            
            # ä¿å­˜æ•°æ®åˆ°CSV
            if self.save_data and markets_data:
                self._save_to_csv(markets_data, "markets_list.csv")
            
            return markets_data
            
        except requests.exceptions.RequestException as e:
            logger.error(f"è·å–å¸‚åœºåˆ—è¡¨å¤±è´¥: {e}")
            return None
    
    def get_market_by_slug(self, slug: str) -> Optional[Dict[str, Any]]:
        """
        æ ¹æ®slugè·å–ç‰¹å®šå¸‚åœº
        
        Args:
            slug: å¸‚åœºslug
            
        Returns:
            å¸‚åœºæ•°æ®æˆ–None
        """
        try:
            url = f"{self.base_url}/markets/{slug}"
            response = self.session.get(url, timeout=10)
            response.raise_for_status()
            
            market_data = response.json()
            logger.info(f"æˆåŠŸè·å–å¸‚åœº: {slug}")
            
            # ä¿å­˜æ•°æ®åˆ°CSV
            if self.save_data and market_data:
                self._save_to_csv([market_data], f"market_{market_slug}.csv")
            
            return market_data
            
        except requests.exceptions.RequestException as e:
            logger.error(f"è·å–å¸‚åœºè¯¦æƒ…å¤±è´¥: {e}")
            return None
    
    def search_events(self, query: str, limit: int = 20) -> Optional[List[Dict[str, Any]]]:
        """
        æœç´¢äº‹ä»¶
        
        Args:
            query: æœç´¢å…³é”®è¯
            limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶
            
        Returns:
            æœç´¢ç»“æœåˆ—è¡¨æˆ–None
        """
        try:
            url = f"{self.base_url}/search"
            params = {
                'query': query,
                'limit': limit,
                'type': 'events'
            }
            
            response = self.session.get(url, params=params, timeout=10)
            response.raise_for_status()
            
            search_results = response.json()
            
            logger.info(f"æœç´¢ '{query}' æ‰¾åˆ° {len(search_results)} ä¸ªç»“æœ")
            
            return search_results
            
        except requests.exceptions.RequestException as e:
            logger.error(f"æœç´¢äº‹ä»¶å¤±è´¥: {e}")
            return None
    
    def get_trending_events(self, limit: int = 10) -> Optional[List[Dict[str, Any]]]:
        """
        è·å–çƒ­é—¨äº‹ä»¶
        
        Args:
            limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶
            
        Returns:
            çƒ­é—¨äº‹ä»¶åˆ—è¡¨æˆ–None
        """
        return self.get_events(active=True, closed=False, limit=limit, order_by='volume', order='desc')
    
    def get_active_events(self, limit: int = 50) -> Optional[List[Dict[str, Any]]]:
        """
        è·å–æ´»è·ƒäº‹ä»¶ (åŸºäºä½ æä¾›çš„APIç«¯ç‚¹)
        
        Args:
            limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶
            
        Returns:
            æ´»è·ƒäº‹ä»¶åˆ—è¡¨æˆ–None
        """
        return self.get_events(active=True, closed=False, limit=limit)
    
    def get_event_markets(self, event_slug: str) -> Optional[List[Dict[str, Any]]]:
        """
        è·å–ç‰¹å®šäº‹ä»¶çš„æ‰€æœ‰å¸‚åœº
        
        Args:
            event_slug: äº‹ä»¶slug
            
        Returns:
            å¸‚åœºåˆ—è¡¨æˆ–None
        """
        return self.get_markets(event_slug=event_slug, active=True)
    
    def get_market_statistics(self, market_slug: str) -> Optional[Dict[str, Any]]:
        """
        è·å–å¸‚åœºç»Ÿè®¡ä¿¡æ¯
        
        Args:
            market_slug: å¸‚åœºslug
            
        Returns:
            ç»Ÿè®¡ä¿¡æ¯æˆ–None
        """
        try:
            url = f"{self.base_url}/markets/{market_slug}/stats"
            response = self.session.get(url, timeout=10)
            response.raise_for_status()
            
            stats_data = response.json()
            logger.info(f"æˆåŠŸè·å–å¸‚åœºç»Ÿè®¡: {market_slug}")
            
            return stats_data
            
        except requests.exceptions.RequestException as e:
            logger.error(f"è·å–å¸‚åœºç»Ÿè®¡å¤±è´¥: {e}")
            return None
    
    def get_market_history(self, market_slug: str, 
                          start_date: Optional[str] = None,
                          end_date: Optional[str] = None) -> Optional[List[Dict[str, Any]]]:
        """
        è·å–å¸‚åœºå†å²æ•°æ®
        
        Args:
            market_slug: å¸‚åœºslug
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
            
        Returns:
            å†å²æ•°æ®åˆ—è¡¨æˆ–None
        """
        try:
            url = f"{self.base_url}/markets/{market_slug}/history"
            params = {}
            
            if start_date:
                params['start_date'] = start_date
            if end_date:
                params['end_date'] = end_date
            
            response = self.session.get(url, params=params, timeout=10)
            response.raise_for_status()
            
            history_data = response.json()
            logger.info(f"æˆåŠŸè·å–å¸‚åœºå†å²: {market_slug}")
            
            # ä¿å­˜æ•°æ®åˆ°CSV
            if self.save_data and history_data:
                self._save_to_csv(history_data, f"history_{market_slug}.csv")
            
            return history_data
            
        except requests.exceptions.RequestException as e:
            logger.error(f"è·å–å¸‚åœºå†å²å¤±è´¥: {e}")
            return None
    
    def get_categories(self) -> Optional[List[Dict[str, Any]]]:
        """
        è·å–äº‹ä»¶åˆ†ç±»
        
        Returns:
            åˆ†ç±»åˆ—è¡¨æˆ–None
        """
        try:
            url = f"{self.base_url}/categories"
            response = self.session.get(url, timeout=10)
            response.raise_for_status()
            
            categories_data = response.json()
            logger.info(f"æˆåŠŸè·å– {len(categories_data)} ä¸ªåˆ†ç±»")
            
            # ä¿å­˜æ•°æ®åˆ°CSV
            if self.save_data and categories_data:
                self._save_to_csv(categories_data, "categories_list.csv")
            
            return categories_data
            
        except requests.exceptions.RequestException as e:
            logger.error(f"è·å–åˆ†ç±»å¤±è´¥: {e}")
            return None
    
    def get_events_by_category(self, category: str, limit: int = 20) -> Optional[List[Dict[str, Any]]]:
        """
        æ ¹æ®åˆ†ç±»è·å–äº‹ä»¶
        
        Args:
            category: åˆ†ç±»åç§°
            limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶
            
        Returns:
            äº‹ä»¶åˆ—è¡¨æˆ–None
        """
        try:
            url = f"{self.base_url}/categories/{category}/events"
            params = {'limit': limit}
            
            response = self.session.get(url, params=params, timeout=10)
            response.raise_for_status()
            
            events_data = response.json()
            logger.info(f"æˆåŠŸè·å–åˆ†ç±» '{category}' ä¸‹çš„ {len(events_data)} ä¸ªäº‹ä»¶")
            
            return events_data
            
        except requests.exceptions.RequestException as e:
            logger.error(f"è·å–åˆ†ç±»äº‹ä»¶å¤±è´¥: {e}")
            return None
    
    def get_high_volume_markets(self, min_volume: float = 1000, limit: int = 20) -> Optional[List[Dict[str, Any]]]:
        """
        è·å–é«˜äº¤æ˜“é‡å¸‚åœº
        
        Args:
            min_volume: æœ€å°äº¤æ˜“é‡
            limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶
            
        Returns:
            é«˜äº¤æ˜“é‡å¸‚åœºåˆ—è¡¨æˆ–None
        """
        markets = self.get_markets(active=True, limit=100, order_by='volume', order='desc')
        
        if not markets:
            return None
        
        # ç­›é€‰é«˜äº¤æ˜“é‡å¸‚åœº
        high_volume_markets = []
        for market in markets:
            volume = market.get('volume', 0)
            if isinstance(volume, (int, float)) and volume >= min_volume:
                high_volume_markets.append(market)
            
            if len(high_volume_markets) >= limit:
                break
        
        logger.info(f"æ‰¾åˆ° {len(high_volume_markets)} ä¸ªé«˜äº¤æ˜“é‡å¸‚åœº")
        return high_volume_markets
    
    def get_near_expiry_markets(self, days: int = 7, limit: int = 20) -> Optional[List[Dict[str, Any]]]:
        """
        è·å–å³å°†åˆ°æœŸçš„å¸‚åœº
        
        Args:
            days: å¤©æ•°èŒƒå›´
            limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶
            
        Returns:
            å³å°†åˆ°æœŸå¸‚åœºåˆ—è¡¨æˆ–None
        """
        markets = self.get_markets(active=True, limit=100)
        
        if not markets:
            return None
        
        from datetime import datetime, timedelta
        
        near_expiry_markets = []
        cutoff_date = datetime.now() + timedelta(days=days)
        
        for market in markets:
            end_date_str = market.get('end_date_iso') or market.get('end_date')
            if end_date_str:
                try:
                    end_date = datetime.fromisoformat(end_date_str.replace('Z', '+00:00'))
                    if end_date <= cutoff_date:
                        near_expiry_markets.append(market)
                except ValueError:
                    continue
            
            if len(near_expiry_markets) >= limit:
                break
        
        logger.info(f"æ‰¾åˆ° {len(near_expiry_markets)} ä¸ªå³å°†åˆ°æœŸçš„å¸‚åœº")
        return near_expiry_markets
    
    def get_market_summary(self, market_slug: str) -> Optional[Dict[str, Any]]:
        """
        è·å–å¸‚åœºæ‘˜è¦ä¿¡æ¯
        
        Args:
            market_slug: å¸‚åœºslug
            
        Returns:
            å¸‚åœºæ‘˜è¦æˆ–None
        """
        market_detail = self.get_market_by_slug(market_slug)
        if not market_detail:
            return None
        
        market_stats = self.get_market_statistics(market_slug)
        
        summary = {
            'market': market_detail,
            'statistics': market_stats,
            'timestamp': datetime.now().isoformat()
        }
        
        return summary
    
    def monitor_events(self, callback_func=None, interval: int = 60):
        """
        ç›‘æ§äº‹ä»¶å˜åŒ–
        
        Args:
            callback_func: å›è°ƒå‡½æ•°ï¼Œæ¥æ”¶äº‹ä»¶æ•°æ®
            interval: ç›‘æ§é—´éš”(ç§’)
        """
        import time
        
        logger.info(f"å¼€å§‹ç›‘æ§äº‹ä»¶ï¼Œé—´éš” {interval} ç§’")
        
        last_events = set()
        
        while True:
            try:
                current_events = self.get_active_events(limit=100)
                
                if current_events:
                    current_event_ids = {event.get('id') or event.get('slug') for event in current_events}
                    
                    # æ£€æµ‹æ–°äº‹ä»¶
                    new_events = current_event_ids - last_events
                    if new_events and callback_func:
                        new_event_data = [e for e in current_events if (e.get('id') or e.get('slug')) in new_events]
                        callback_func(new_event_data)
                    
                    last_events = current_event_ids
                
                time.sleep(interval)
                
            except KeyboardInterrupt:
                logger.info("ç›‘æ§å·²åœæ­¢")
                break
            except Exception as e:
                logger.error(f"ç›‘æ§è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
                time.sleep(10)

def main():
    """æµ‹è¯•å‡½æ•°"""
    client = PolymarketMarketClient(save_data=True)
    
    print("ğŸ” æµ‹è¯•Polymarket Market APIå®¢æˆ·ç«¯")
    print("=" * 50)
    
    # æµ‹è¯•è·å–æ´»è·ƒäº‹ä»¶ (åŸºäºä½ æä¾›çš„API)
    print("\n1. è·å–æ´»è·ƒäº‹ä»¶ (active=true&closed=false&limit=5):")
    events = client.get_active_events(limit=5)
    if events:
        print(f"âœ… æˆåŠŸè·å– {len(events)} ä¸ªæ´»è·ƒäº‹ä»¶")
        for i, event in enumerate(events[:3], 1):
            title = event.get('title') or event.get('name', 'N/A')
            slug = event.get('slug', 'N/A')
            print(f"  {i}. {title[:50]}...")
            print(f"     Slug: {slug}")
    else:
        print("âŒ è·å–æ´»è·ƒäº‹ä»¶å¤±è´¥")
    
    # æµ‹è¯•è·å–å¸‚åœº
    print("\n2. è·å–æ´»è·ƒå¸‚åœº:")
    markets = client.get_markets(active=True, closed=False, limit=5)
    if markets:
        print(f"âœ… æˆåŠŸè·å– {len(markets)} ä¸ªå¸‚åœº")
        for i, market in enumerate(markets[:3], 1):
            question = market.get('question') or market.get('title', 'N/A')
            slug = market.get('slug', 'N/A')
            print(f"  {i}. {question[:50]}...")
            print(f"     Slug: {slug}")
    else:
        print("âŒ è·å–å¸‚åœºå¤±è´¥")
    
    # æµ‹è¯•æœç´¢åŠŸèƒ½
    print("\n3. æœç´¢äº‹ä»¶:")
    search_results = client.search_events("election", limit=3)
    if search_results:
        print(f"âœ… æœç´¢åˆ° {len(search_results)} ä¸ªç»“æœ")
        for i, result in enumerate(search_results[:2], 1):
            title = result.get('title') or result.get('name', 'N/A')
            print(f"  {i}. {title[:50]}...")
    else:
        print("âŒ æœç´¢å¤±è´¥")
    
    # æµ‹è¯•è·å–åˆ†ç±»
    print("\n4. è·å–åˆ†ç±»:")
    categories = client.get_categories()
    if categories:
        print(f"âœ… æˆåŠŸè·å– {len(categories)} ä¸ªåˆ†ç±»")
        for i, category in enumerate(categories[:3], 1):
            name = category.get('name', 'N/A')
            print(f"  {i}. {name}")
    else:
        print("âŒ è·å–åˆ†ç±»å¤±è´¥")
    
    print(f"\nğŸ“ æ•°æ®å·²ä¿å­˜åˆ° ./data/ ç›®å½•")

if __name__ == "__main__":
    main()